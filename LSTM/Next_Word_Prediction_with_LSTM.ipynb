{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZbcnlrV260B",
        "outputId": "6eb4d768-9003-4978-8f7f-38784e669e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "[Dataset](https://www.kaggle.com/datasets/ronikdedhia/next-word-prediction/code)"
      ],
      "metadata": {
        "id": "0lzBrS-k58Qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path):\n",
        "    with open(path) as file:\n",
        "        text = file.read()\n",
        "    return text[:5000]"
      ],
      "metadata": {
        "id": "nZ48GgGl8dVX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "xz5qrZh73vDs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = en_core_web_sm.load()"
      ],
      "metadata": {
        "id": "TqhXZFElMpYc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\ufeff\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "metadata": {
        "id": "pXdNNo4hBCFX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_file('data.txt')\n",
        "tokens = separate_punc(data)\n",
        "tokens[:10]"
      ],
      "metadata": {
        "id": "HS2CylyeBCIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24667b3-1fe2-46bd-886f-1b2aa821c0f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['project',\n",
              " 'gutenberg',\n",
              " \"'s\",\n",
              " 'the',\n",
              " 'adventures',\n",
              " 'of',\n",
              " 'sherlock',\n",
              " 'holmes',\n",
              " 'by',\n",
              " 'arthur']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dQinlSmCiaE",
        "outputId": "e0984bfd-85f2-4aab-c9dd-929356ea929e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "912"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = 20\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "    seq = tokens[i-train_len:i]\n",
        "    text_sequences.append(seq)"
      ],
      "metadata": {
        "id": "tairalbkCijs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-uCd4d86LqUB",
        "outputId": "78467209-8dda-4e29-fffe-8ff8ec2e89fd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"project gutenberg 's the adventures of sherlock holmes by arthur conan doyle this ebook is for the use of anyone\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7A1X_qweL9gq",
        "outputId": "c3a08cda-f656-4752-85ec-23d71e357c94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"gutenberg 's the adventures of sherlock holmes by arthur conan doyle this ebook is for the use of anyone anywhere\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hs_D8TdYMLc4",
        "outputId": "aaf6cb15-0341-4f9d-ab02-5c5467ae1800"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"'s the adventures of sherlock holmes by arthur conan doyle this ebook is for the use of anyone anywhere at\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "metadata": {
        "id": "br0jK1nlMVL0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "vocabulary_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbq4z1vLOk6G",
        "outputId": "b461a8f4-6111-492e-8e06-112f48669279"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sequences[0]))\n",
        "print(sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W93EdS_MV2L",
        "outputId": "e0b063f7-651d-4e0d-fcc3-9365e7dfa574"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "[39, 38, 445, 1, 37, 2, 28, 14, 27, 53, 52, 51, 50, 36, 104, 19, 1, 103, 2, 106]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for a in tokenizer.index_word:\n",
        "    print(a,\"--->\",tokenizer.index_word[a])\n",
        "    i+=1\n",
        "    if i==20 : break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVUmmz_SMV4i",
        "outputId": "aede1a03-de00-41c3-c0c7-91f13895543c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ---> the\n",
            "2 ---> of\n",
            "3 ---> and\n",
            "4 ---> his\n",
            "5 ---> a\n",
            "6 ---> to\n",
            "7 ---> was\n",
            "8 ---> in\n",
            "9 ---> i\n",
            "10 ---> he\n",
            "11 ---> with\n",
            "12 ---> \n",
            "   \n",
            "13 ---> my\n",
            "14 ---> holmes\n",
            "15 ---> it\n",
            "16 ---> own\n",
            "17 ---> which\n",
            "18 ---> had\n",
            "19 ---> for\n",
            "20 ---> \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences[0]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-HtVVaWMV6-",
        "outputId": "bf315b9e-b8e0-4cf1-a970-1c66106ef534"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39 : project\n",
            "38 : gutenberg\n",
            "445 : 's\n",
            "1 : the\n",
            "37 : adventures\n",
            "2 : of\n",
            "28 : sherlock\n",
            "14 : holmes\n",
            "27 : by\n",
            "53 : arthur\n",
            "52 : conan\n",
            "51 : doyle\n",
            "50 : this\n",
            "36 : ebook\n",
            "104 : is\n",
            "19 : for\n",
            "1 : the\n",
            "103 : use\n",
            "2 : of\n",
            "106 : anyone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWd28dxkMV93",
        "outputId": "b5c23c8f-4c64-44bc-b15b-7fa8cf20d3e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 39,  38, 445, ..., 103,   2, 106],\n",
              "       [ 38, 445,   1, ...,   2, 106, 107],\n",
              "       [445,   1,  37, ..., 106, 107,  30],\n",
              "       ...,\n",
              "       [  2, 436,   3, ...,   1, 444,   3],\n",
              "       [436,   3, 437, ..., 444,   3, 105],\n",
              "       [  3, 437,   5, ...,   3, 105,  29]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = sequences[:,:-1]"
      ],
      "metadata": {
        "id": "tt8-ZFzNRZQU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "t3AFRjwARaPg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1H6lbCsPQ-B",
        "outputId": "9dcd6dbd-d80a-42ae-e4c3-15640f15f7ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(892, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LNscrREPRAo",
        "outputId": "ab6f80dd-6f8b-46b0-cdf8-92fe3b3b4c1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(892,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=vocabulary_size)"
      ],
      "metadata": {
        "id": "Oc9QqVdeRfaJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3i-iFkzRfcb",
        "outputId": "880e735e-64cf-4fe8-9820-483f4067c2f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(892, 445)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = X.shape[1]\n",
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwC3GVjdV-mQ",
        "outputId": "310dec92-1f09-4b42-a7d2-bf3e71e2dbf3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "metadata": {
        "id": "Ke0IjzIsRffW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 30, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "x6f1_COrRfiK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocabulary_size, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGzdCnGDRfkv",
        "outputId": "af95ed59-b18f-4f2c-e97d-9c188aac04ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 19, 30)            13350     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 19, 150)           108600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 150)               22650     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 445)               67195     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 392395 (1.50 MB)\n",
            "Trainable params: 392395 (1.50 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X, y, epochs=140,verbose=1,validation_batch_size=.20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0js4465WF17",
        "outputId": "493c9824-b4c3-400c-889a-eb8bef9dfaf9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/140\n",
            "28/28 [==============================] - 7s 105ms/step - loss: 5.9583 - accuracy: 0.0583\n",
            "Epoch 2/140\n",
            "28/28 [==============================] - 4s 132ms/step - loss: 5.5993 - accuracy: 0.0639\n",
            "Epoch 3/140\n",
            "28/28 [==============================] - 1s 51ms/step - loss: 5.5034 - accuracy: 0.0639\n",
            "Epoch 4/140\n",
            "28/28 [==============================] - 2s 58ms/step - loss: 5.4727 - accuracy: 0.0639\n",
            "Epoch 5/140\n",
            "28/28 [==============================] - 1s 26ms/step - loss: 5.4519 - accuracy: 0.0639\n",
            "Epoch 6/140\n",
            "28/28 [==============================] - 1s 41ms/step - loss: 5.4660 - accuracy: 0.0639\n",
            "Epoch 7/140\n",
            "28/28 [==============================] - 1s 25ms/step - loss: 5.4361 - accuracy: 0.0639\n",
            "Epoch 8/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 5.4141 - accuracy: 0.0628\n",
            "Epoch 9/140\n",
            "28/28 [==============================] - 1s 26ms/step - loss: 5.4205 - accuracy: 0.0639\n",
            "Epoch 10/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 5.3564 - accuracy: 0.0673\n",
            "Epoch 11/140\n",
            "28/28 [==============================] - 1s 19ms/step - loss: 5.2699 - accuracy: 0.0706\n",
            "Epoch 12/140\n",
            "28/28 [==============================] - 1s 14ms/step - loss: 5.1948 - accuracy: 0.0717\n",
            "Epoch 13/140\n",
            "28/28 [==============================] - 1s 20ms/step - loss: 5.1372 - accuracy: 0.0740\n",
            "Epoch 14/140\n",
            "28/28 [==============================] - 1s 20ms/step - loss: 5.0617 - accuracy: 0.0841\n",
            "Epoch 15/140\n",
            "28/28 [==============================] - 1s 19ms/step - loss: 4.9851 - accuracy: 0.0807\n",
            "Epoch 16/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 4.9146 - accuracy: 0.0774\n",
            "Epoch 17/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.8456 - accuracy: 0.0830\n",
            "Epoch 18/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 4.7890 - accuracy: 0.0897\n",
            "Epoch 19/140\n",
            "28/28 [==============================] - 1s 21ms/step - loss: 4.7265 - accuracy: 0.0818\n",
            "Epoch 20/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 4.6621 - accuracy: 0.0818\n",
            "Epoch 21/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 4.6309 - accuracy: 0.0863\n",
            "Epoch 22/140\n",
            "28/28 [==============================] - 1s 29ms/step - loss: 4.5863 - accuracy: 0.0852\n",
            "Epoch 23/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 4.5331 - accuracy: 0.0830\n",
            "Epoch 24/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 4.4493 - accuracy: 0.0796\n",
            "Epoch 25/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 4.4198 - accuracy: 0.0964\n",
            "Epoch 26/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 4.3626 - accuracy: 0.0919\n",
            "Epoch 27/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 4.3125 - accuracy: 0.0908\n",
            "Epoch 28/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.3000 - accuracy: 0.0930\n",
            "Epoch 29/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.2535 - accuracy: 0.0886\n",
            "Epoch 30/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.2208 - accuracy: 0.0942\n",
            "Epoch 31/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 4.1866 - accuracy: 0.1065\n",
            "Epoch 32/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.2136 - accuracy: 0.0886\n",
            "Epoch 33/140\n",
            "28/28 [==============================] - 0s 15ms/step - loss: 4.1911 - accuracy: 0.0897\n",
            "Epoch 34/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.1711 - accuracy: 0.0930\n",
            "Epoch 35/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 4.0970 - accuracy: 0.0886\n",
            "Epoch 36/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 4.0336 - accuracy: 0.1043\n",
            "Epoch 37/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.0387 - accuracy: 0.1031\n",
            "Epoch 38/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 4.0455 - accuracy: 0.0897\n",
            "Epoch 39/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 3.9755 - accuracy: 0.1099\n",
            "Epoch 40/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 3.9327 - accuracy: 0.1043\n",
            "Epoch 41/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.8999 - accuracy: 0.1065\n",
            "Epoch 42/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 3.8678 - accuracy: 0.1009\n",
            "Epoch 43/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.8592 - accuracy: 0.1177\n",
            "Epoch 44/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.8561 - accuracy: 0.1143\n",
            "Epoch 45/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.8071 - accuracy: 0.1166\n",
            "Epoch 46/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.9205 - accuracy: 0.0953\n",
            "Epoch 47/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 3.8250 - accuracy: 0.1155\n",
            "Epoch 48/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.8050 - accuracy: 0.1121\n",
            "Epoch 49/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.7835 - accuracy: 0.1177\n",
            "Epoch 50/140\n",
            "28/28 [==============================] - 0s 15ms/step - loss: 3.7221 - accuracy: 0.1222\n",
            "Epoch 51/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.6693 - accuracy: 0.1289\n",
            "Epoch 52/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.6285 - accuracy: 0.1278\n",
            "Epoch 53/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 3.6512 - accuracy: 0.1334\n",
            "Epoch 54/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 3.6050 - accuracy: 0.1300\n",
            "Epoch 55/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 3.5569 - accuracy: 0.1379\n",
            "Epoch 56/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.5420 - accuracy: 0.1379\n",
            "Epoch 57/140\n",
            "28/28 [==============================] - 0s 15ms/step - loss: 3.5034 - accuracy: 0.1469\n",
            "Epoch 58/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.5017 - accuracy: 0.1300\n",
            "Epoch 59/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 3.4721 - accuracy: 0.1401\n",
            "Epoch 60/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 3.4484 - accuracy: 0.1357\n",
            "Epoch 61/140\n",
            "28/28 [==============================] - 0s 16ms/step - loss: 3.3540 - accuracy: 0.1513\n",
            "Epoch 62/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 3.3522 - accuracy: 0.1592\n",
            "Epoch 63/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.3597 - accuracy: 0.1547\n",
            "Epoch 64/140\n",
            "28/28 [==============================] - 1s 20ms/step - loss: 3.2712 - accuracy: 0.1704\n",
            "Epoch 65/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.2141 - accuracy: 0.1726\n",
            "Epoch 66/140\n",
            "28/28 [==============================] - 1s 21ms/step - loss: 3.1895 - accuracy: 0.1760\n",
            "Epoch 67/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 3.1135 - accuracy: 0.1951\n",
            "Epoch 68/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.0968 - accuracy: 0.1839\n",
            "Epoch 69/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 3.0607 - accuracy: 0.1917\n",
            "Epoch 70/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 2.9987 - accuracy: 0.2040\n",
            "Epoch 71/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 2.9369 - accuracy: 0.2085\n",
            "Epoch 72/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.9601 - accuracy: 0.2096\n",
            "Epoch 73/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.8016 - accuracy: 0.2422\n",
            "Epoch 74/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.7205 - accuracy: 0.2556\n",
            "Epoch 75/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.6881 - accuracy: 0.2578\n",
            "Epoch 76/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 2.6744 - accuracy: 0.2545\n",
            "Epoch 77/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.7325 - accuracy: 0.2444\n",
            "Epoch 78/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.6794 - accuracy: 0.2578\n",
            "Epoch 79/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.5143 - accuracy: 0.2926\n",
            "Epoch 80/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.4308 - accuracy: 0.3105\n",
            "Epoch 81/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.4019 - accuracy: 0.3038\n",
            "Epoch 82/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.2981 - accuracy: 0.3206\n",
            "Epoch 83/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.2507 - accuracy: 0.3487\n",
            "Epoch 84/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 2.1261 - accuracy: 0.3733\n",
            "Epoch 85/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.1222 - accuracy: 0.3778\n",
            "Epoch 86/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.0814 - accuracy: 0.3845\n",
            "Epoch 87/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 2.0362 - accuracy: 0.4058\n",
            "Epoch 88/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.9497 - accuracy: 0.4271\n",
            "Epoch 89/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 1.9196 - accuracy: 0.4283\n",
            "Epoch 90/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.8307 - accuracy: 0.4339\n",
            "Epoch 91/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.7636 - accuracy: 0.4585\n",
            "Epoch 92/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.6501 - accuracy: 0.5135\n",
            "Epoch 93/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.5996 - accuracy: 0.5202\n",
            "Epoch 94/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.6639 - accuracy: 0.5045\n",
            "Epoch 95/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.5654 - accuracy: 0.5314\n",
            "Epoch 96/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.4777 - accuracy: 0.5583\n",
            "Epoch 97/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.4592 - accuracy: 0.5818\n",
            "Epoch 98/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.3783 - accuracy: 0.5874\n",
            "Epoch 99/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.3198 - accuracy: 0.5964\n",
            "Epoch 100/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 1.2583 - accuracy: 0.6278\n",
            "Epoch 101/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.1628 - accuracy: 0.6749\n",
            "Epoch 102/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.1134 - accuracy: 0.6827\n",
            "Epoch 103/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 1.1118 - accuracy: 0.6682\n",
            "Epoch 104/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.0530 - accuracy: 0.6984\n",
            "Epoch 105/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 1.0381 - accuracy: 0.7175\n",
            "Epoch 106/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.9696 - accuracy: 0.7242\n",
            "Epoch 107/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.8940 - accuracy: 0.7388\n",
            "Epoch 108/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.8181 - accuracy: 0.7848\n",
            "Epoch 109/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.7787 - accuracy: 0.7904\n",
            "Epoch 110/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.7544 - accuracy: 0.7848\n",
            "Epoch 111/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.7163 - accuracy: 0.8083\n",
            "Epoch 112/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.6830 - accuracy: 0.8195\n",
            "Epoch 113/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.7221 - accuracy: 0.7937\n",
            "Epoch 114/140\n",
            "28/28 [==============================] - 0s 11ms/step - loss: 0.7368 - accuracy: 0.8027\n",
            "Epoch 115/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.6959 - accuracy: 0.8072\n",
            "Epoch 116/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.6344 - accuracy: 0.8285\n",
            "Epoch 117/140\n",
            "28/28 [==============================] - 0s 12ms/step - loss: 0.6682 - accuracy: 0.8016\n",
            "Epoch 118/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.5676 - accuracy: 0.8498\n",
            "Epoch 119/140\n",
            "28/28 [==============================] - 0s 13ms/step - loss: 0.5503 - accuracy: 0.8576\n",
            "Epoch 120/140\n",
            "28/28 [==============================] - 1s 21ms/step - loss: 0.5016 - accuracy: 0.8789\n",
            "Epoch 121/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4283 - accuracy: 0.8913\n",
            "Epoch 122/140\n",
            "28/28 [==============================] - 0s 14ms/step - loss: 0.3885 - accuracy: 0.9070\n",
            "Epoch 123/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3745 - accuracy: 0.9148\n",
            "Epoch 124/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.9170\n",
            "Epoch 125/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4171 - accuracy: 0.9070\n",
            "Epoch 126/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.8688\n",
            "Epoch 127/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.8834\n",
            "Epoch 128/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.4397 - accuracy: 0.8890\n",
            "Epoch 129/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.3913 - accuracy: 0.9137\n",
            "Epoch 130/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.8767\n",
            "Epoch 131/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.4447 - accuracy: 0.8778\n",
            "Epoch 132/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.3434 - accuracy: 0.9226\n",
            "Epoch 133/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.2603 - accuracy: 0.9462\n",
            "Epoch 134/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1808 - accuracy: 0.9709\n",
            "Epoch 135/140\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 0.1553 - accuracy: 0.9709\n",
            "Epoch 136/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.1323 - accuracy: 0.9821\n",
            "Epoch 137/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1167 - accuracy: 0.9854\n",
            "Epoch 138/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.1074 - accuracy: 0.9877\n",
            "Epoch 139/140\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 0.0980 - accuracy: 0.9888\n",
            "Epoch 140/140\n",
            "28/28 [==============================] - 0s 10ms/step - loss: 0.0875 - accuracy: 0.9933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "utClbdOObkjQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    output_text = []\n",
        "    input_text = seed_text\n",
        "    for i in range(num_gen_words):\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        predict_x=model.predict(pad_encoded)\n",
        "        pred_word_ind=np.argmax(predict_x,axis=1)[0]\n",
        "        pred_word = tokenizer.index_word[pred_word_ind]\n",
        "        input_text += ' ' + pred_word\n",
        "        output_text.append(pred_word)\n",
        "\n",
        "    return ' '.join(output_text)"
      ],
      "metadata": {
        "id": "45I-QcedWF4D"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_pick = random.randint(0,len(text_sequences))\n",
        "random_pick"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8si7TQDbwtg",
        "outputId": "85294f13-6a11-4c2c-a757-6edef4d34772"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "837"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed_text = text_sequences[random_pick]\n",
        "print(random_seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHLB8hJabwwO",
        "outputId": "c2099d52-b300-48b9-b686-183fed956f1a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'was', 'shown', 'up', 'to', 'the', 'chamber', 'which', 'had', 'formerly', 'been', 'in', 'part', 'my', 'own', 'his', 'manner', 'was', 'not', 'effusive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = ' '.join(random_seed_text)\n",
        "seed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0Gy3hJU1bwz2",
        "outputId": "342f3281-1109-4d6c-f8d4-55d02ade5020"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and was shown up to the chamber which had formerly been in part my own his manner was not effusive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "ITvUKruxbw27",
        "outputId": "022012da-8ac3-4fb0-802b-e0912f1cb74f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it seldom was but he was glad i think to'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='Hi, i am sheldon, who are'\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO5uZ-SPbw5k",
        "outputId": "abf022d4-4bf1-4f02-dc97-17ea9771ae46"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, i am sheldon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=text,num_gen_words=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "tG11INtzddIo",
        "outputId": "0c72f0fd-ab92-4b14-dfb4-c1eb4e9d1e5f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'little as'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}